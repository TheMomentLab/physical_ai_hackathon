# π¤— PEFTλ΅ νλΌλ―Έν„° ν¨μ¨μ  νμΈνλ‹

[π¤— PEFT](https://github.com/huggingface/peft) (Parameter-Efficient Fine-Tuning)λ” λ€ν• μ‚¬μ „ν•™μµ λ¨λΈ(μ: SmolVLA, Ο€β‚€ λ“±)μ„ λ¨λ“  νλΌλ―Έν„°λ¥Ό ν•™μµν•μ§€ μ•κ³ λ„ μƒλ΅μ΄ νƒμ¤ν¬μ— ν¨μ¨μ μΌλ΅ μ μ‘μ‹ν‚¤λ” λΌμ΄λΈλ¬λ¦¬μ΄λ©°, μ„±λ¥μ€ μ μ‚¬ν• μμ¤€μ„ μ μ§€ν•  μ μμµλ‹λ‹¤.

PEFT μ§€μ›μ„ ν™μ„±ν™”ν•λ ¤λ©΄ `lerobot[peft]` μµμ… ν¨ν‚¤μ§€λ¥Ό μ„¤μΉν•μ„Έμ”.

μ μ© κ°€λ¥ν• λ¨λ“  μ–΄λ‘ν…μ΄μ… λ°©λ²•μ€ [π¤— PEFT λ¬Έμ„](https://huggingface.co/docs/peft/index)λ¥Ό μ°Έκ³ ν•μ„Έμ”.

## SmolVLA ν•™μµ

μ΄ μ„Ήμ…μ—μ„λ” libero λ°μ΄ν„°μ…‹μ—μ„ μ‚¬μ „ν•™μµλ SmolVLA μ •μ±…μ„ PEFTλ΅ ν•™μµν•λ” λ°©λ²•μ„ λ³΄μ—¬μ¤λ‹λ‹¤.
κ°„λ‹¨ν `libero_spatial` μ„λΈμ…‹λ§ μ‚¬μ©ν•λ©°, `lerobot/smolvla_base`λ¥Ό νλΌλ―Έν„° ν¨μ¨μ  νμΈνλ‹ λ€μƒμΌλ΅ μ‚¬μ©ν•©λ‹λ‹¤:

```
lerobot-train \
 --policy.path=lerobot/smolvla_base \
 --policy.repo_id=your_hub_name/my_libero_smolvla \
 --dataset.repo_id=HuggingFaceVLA/libero \
 --policy.output_features=null \
 --policy.input_features=null \
 --policy.optimizer_lr=1e-3 \
 --policy.scheduler_decay_lr=1e-4 \
 --env.type=libero \
 --env.task=libero_spatial \
 --steps=100000 \
 --batch_size=32 \
 --peft.method_type=LORA \
 --peft.r=64
```

`--peft.method_type`λ΅ μ‚¬μ©ν•  PEFT λ°©λ²•μ„ μ„ νƒν•©λ‹λ‹¤. μ—¬κΈ°μ„λ” κ°€μ¥ λ„λ¦¬ μ“°μ΄λ”
[LoRA](https://huggingface.co/docs/peft/main/en/package_reference/lora) (Low-Rank Adapter)λ¥Ό μ‚¬μ©ν•©λ‹λ‹¤.
Low-rank μ μ‘μ€ μ „μ²΄ κ°€μ¤‘μΉ ν–‰λ ¬ λ€μ‹  λΉ„κµμ  λ‚®μ€ rankμ ν–‰λ ¬λ§ ν•™μµν•λ‹¤λ” μλ―Έμ…λ‹λ‹¤. μ΄ rankλ”
`--peft.r`λ΅ μ§€μ •ν•λ©°, κ°’μ΄ λ†’μ„μλ΅ μ „μ²΄ νμΈνλ‹μ— κ°€κΉμ›μ§‘λ‹λ‹¤.

λ” λ³µμ΅ν•(νλΌλ―Έν„° μκ°€ λ§μ€) λ°©λ²•λ„ μμ§€λ§, μ•„μ§ μ§€μ›λμ§€ μ•μµλ‹λ‹¤. μ›ν•λ” PEFT λ°©λ²•μ΄ μλ‹¤λ©΄ μ΄μλ¥Ό λ“±λ΅ν•΄ μ£Όμ„Έμ”.

κΈ°λ³Έμ μΌλ΅ PEFTλ” SmolVLAμ LM expertμ— μλ” `q_proj`, `v_proj` λ μ΄μ–΄λ¥Ό λ€μƒμΌλ΅ ν•©λ‹λ‹¤.
λν• νƒμ¤ν¬ μμ΅΄μ„±μ΄ λ†’μ€ state/action projection ν–‰λ ¬λ„ λ€μƒμΌλ΅ μ„¤μ •λ©λ‹λ‹¤.
λ‹¤λ¥Έ λ μ΄μ–΄λ¥Ό λ€μƒμΌλ΅ ν•κ³  μ‹¶λ‹¤λ©΄ `--peft.target_modules`λ΅ μ§€μ •ν•  μ μμµλ‹λ‹¤.
κ° PEFT λ°©λ²•μ λ¬Έμ„μ—μ„ μ§€μ› μ…λ ¥ ν•μ‹μ„ ν™•μΈν•μ„Έμ”(μ: [LoRA target_modules λ¬Έμ„](https://huggingface.co/docs/peft/main/en/package_reference/lora#peft.LoraConfig.target_modules)).
λ³΄ν†µ suffix λ¦¬μ¤νΈλ‚ μ •κ·μ‹μ„ μ§€μ›ν•©λ‹λ‹¤. μλ¥Ό λ“¤μ–΄ `lm_expert`μ q/v λ€μ‹  MLPλ¥Ό λ€μƒμΌλ΅ ν•λ ¤λ©΄:

```
--peft.target_modules='(model\.vlm_with_expert\.lm_expert\..*\.(down|gate|up)_proj|.*\.(state_proj|action_in_proj|action_out_proj|action_time_mlp_in|action_time_mlp_out))'
```

μ–΄λ–¤ λ μ΄μ–΄λ” μ μ‘μ΄ μ•„λ‹λΌ μ „μ²΄ νμΈνλ‹μ΄ ν•„μ”ν•  μ μμµλ‹λ‹¤. μ΄ κ²½μ° `--peft.full_training_modules`μ—
λ μ΄μ–΄ suffix λ©λ΅μ„ μ „λ‹¬ν•λ©΄ λ©λ‹λ‹¤:

```
--peft.full_training_modules=["state_proj"]
```

μΌλ°μ μΌλ΅ LoRAλ¥Ό μ‚¬μ©ν•λ©΄ ν•™μµλ¥ κ³Ό μ¤μΌ€μ¤„λ¬ λ©ν‘ ν•™μµλ¥ μ„ μ „μ²΄ νμΈνλ‹ λ€λΉ„ 10λ°° μ •λ„ λ†’μ—¬λ„ λ©λ‹λ‹¤
(μ: μΌλ° 1e-4 β†’ LoRA 1e-3).
